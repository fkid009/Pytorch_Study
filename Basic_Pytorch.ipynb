{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyMWq5hK0AGayUja+4MzJAoC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"JIjbmsaJwDAs","executionInfo":{"status":"ok","timestamp":1707179565922,"user_tz":-540,"elapsed":4844,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"outputs":[],"source":["import torch"]},{"cell_type":"code","source":["print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLQovlZ4zXIg","executionInfo":{"status":"ok","timestamp":1707179565922,"user_tz":-540,"elapsed":15,"user":{"displayName":"해빈임","userId":"11652320193016134538"}},"outputId":"982e8c1b-9e6c-4a21-9225-f472e403bf56"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["2.1.0+cu121\n"]}]},{"cell_type":"code","source":["dtype = torch.float\n","# device  = torch.device(\"cpu\")\n","device = torch.device(\"cuda:0\") # For GPU"],"metadata":{"id":"bEZ0HKHQzdLO","executionInfo":{"status":"ok","timestamp":1707183919043,"user_tz":-540,"elapsed":954,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["# Data Generation"],"metadata":{"id":"A_ZBCH5SCx-T"}},{"cell_type":"code","source":["N, D_in, H, D_out = 64, 1000, 100, 10 # batch_size, input_dimension, hidden_dimension, output_dimension"],"metadata":{"id":"ysBTqOzrziKd","executionInfo":{"status":"ok","timestamp":1707183922002,"user_tz":-540,"elapsed":515,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["x = torch.randn(N, D_in, device = device, dtype = dtype)\n","y = torch.randn(N, D_out, device = device, dtype = dtype)"],"metadata":{"id":"f5p2uxkt0Jqh","executionInfo":{"status":"ok","timestamp":1707183922983,"user_tz":-540,"elapsed":16,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["# Initialization"],"metadata":{"id":"PYEKMJuuCvUk"}},{"cell_type":"code","source":["w1 = torch.randn(D_in, H, device = device, dtype = dtype)\n","w2 = torch.randn(H, D_out, device = device, dtype = dtype)"],"metadata":{"id":"1I1hJmR7CN-g","executionInfo":{"status":"ok","timestamp":1707182982790,"user_tz":-540,"elapsed":539,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["learning_rate = 1e-6"],"metadata":{"id":"Ii7Shs3A0_XA","executionInfo":{"status":"ok","timestamp":1707182940307,"user_tz":-540,"elapsed":16,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Neural Netowork in Low-level"],"metadata":{"id":"nP-8Te_LBDKX"}},{"cell_type":"code","source":["for i in range(1000):\n","    h = x.mm(w1)\n","    h_relu = h.clamp(min = 0)\n","    y_pred = h_relu.mm(w2)\n","\n","    loss = (y_pred - y).pow(2).mean()\n","    if i % 100 == 99:\n","        print(f\"Epoch: {i}, Train_loss: {loss}\")\n","\n","    grad_y_pred = 2.0 * (y_pred - y)\n","    grad_w2 = h_relu.t().mm(grad_y_pred)\n","    grad_h_relu = grad_y_pred.mm(w2.t())\n","    grad_h = grad_h_relu.clone()\n","    grad_h[h < 0] = 0\n","    grad_w1 = x.t().mm(grad_h)\n","\n","    w1 -= learning_rate * grad_w1\n","    w2 -= learning_rate * grad_w2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ApJPgiF8BKf4","executionInfo":{"status":"ok","timestamp":1707182985883,"user_tz":-540,"elapsed":557,"user":{"displayName":"해빈임","userId":"11652320193016134538"}},"outputId":"7499d0d5-b6a2-4953-d74f-bd74967e1f81"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 99, Train_loss: 0.4643843173980713\n","Epoch: 199, Train_loss: 0.000989199266768992\n","Epoch: 299, Train_loss: 4.52483982371632e-06\n","Epoch: 399, Train_loss: 1.7088237314055732e-07\n","Epoch: 499, Train_loss: 4.0151668656562833e-08\n","Epoch: 599, Train_loss: 1.8395201806242767e-08\n","Epoch: 699, Train_loss: 1.1483979101001296e-08\n","Epoch: 799, Train_loss: 8.430783182689083e-09\n","Epoch: 899, Train_loss: 6.5176295471758294e-09\n","Epoch: 999, Train_loss: 5.205746056446969e-09\n"]}]},{"cell_type":"markdown","source":["# Neural Netowork using autograd"],"metadata":{"id":"cPrrR_eiCWCU"}},{"cell_type":"code","source":["w1 = torch.randn(D_in, H, device = device, dtype = dtype, requires_grad=True)\n","w2 = torch.randn(H, D_out, device = device, dtype = dtype, requires_grad = True)"],"metadata":{"id":"2HUEmvj4CVmQ","executionInfo":{"status":"ok","timestamp":1707183929471,"user_tz":-540,"elapsed":403,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["for i in range(1000):\n","    y_pred = x.mm(w1).clamp(min = 0).mm(w2)\n","\n","    loss = (y_pred - y).pow(2).mean()\n","    if i % 100 == 99:\n","        print(f\"Epoch: {i}, Train_loss: {loss}\")\n","\n","    loss.backward() # This call will compute the gradient of loss with repect to all Tensors with requires_grad=True.\n","\n","    with torch.no_grad():\n","        w1 -= learning_rate * w1.grad\n","        w2 -= learning_rate * w2.grad\n","\n","        w1.grad.zero_()\n","        w2.grad.zero_()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A9bZaXZE1SgN","executionInfo":{"status":"ok","timestamp":1707183043913,"user_tz":-540,"elapsed":863,"user":{"displayName":"해빈임","userId":"11652320193016134538"}},"outputId":"72292027-f02b-4d35-a472-150828ad1516"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 99, Train_loss: 39147.33984375\n","Epoch: 199, Train_loss: 33573.3671875\n","Epoch: 299, Train_loss: 29918.037109375\n","Epoch: 399, Train_loss: 27298.453125\n","Epoch: 499, Train_loss: 25265.076171875\n","Epoch: 599, Train_loss: 23581.677734375\n","Epoch: 699, Train_loss: 22124.16015625\n","Epoch: 799, Train_loss: 20826.115234375\n","Epoch: 899, Train_loss: 19648.712890625\n","Epoch: 999, Train_loss: 18569.271484375\n"]}]},{"cell_type":"markdown","source":["# Defining new autograd functions"],"metadata":{"id":"ez5o2eppClCc"}},{"cell_type":"code","source":["class MyReLU(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, input):\n","        ctx.save_for_backward(input)\n","        return input.clamp(min = 0)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        input, = ctx.saved_tensors\n","        grad_input = grad_output.clone()\n","        grad_input[input < 0] = 0\n","        return grad_input"],"metadata":{"id":"VPiA1Jnn5U8W","executionInfo":{"status":"ok","timestamp":1707183397850,"user_tz":-540,"elapsed":516,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["for i in range(1000):\n","    relu = MyReLU.apply\n","\n","    y_pred = relu(x.mm(w1)).mm(w2)\n","\n","    loss = (y_pred - y).pow(2).mean()\n","    if i % 100 == 99:\n","        print(f\"Epoch: {i}, Train_loss: {loss}\")\n","\n","    loss.backward() # This call will compute the gradient of loss with repect to all Tensors with requires_grad=True.\n","\n","    with torch.no_grad():\n","        w1 -= learning_rate * w1.grad\n","        w2 -= learning_rate * w2.grad\n","\n","        w1.grad.zero_()\n","        w2.grad.zero_()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oqbOwTFlDg-x","executionInfo":{"status":"ok","timestamp":1707183399460,"user_tz":-540,"elapsed":956,"user":{"displayName":"해빈임","userId":"11652320193016134538"}},"outputId":"792aebf1-d38d-4e89-f25c-c93db5132232"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 99, Train_loss: 17567.919921875\n","Epoch: 199, Train_loss: 16644.458984375\n","Epoch: 299, Train_loss: 15785.390625\n","Epoch: 399, Train_loss: 14985.8662109375\n","Epoch: 499, Train_loss: 14239.9345703125\n","Epoch: 599, Train_loss: 13542.548828125\n","Epoch: 699, Train_loss: 12890.021484375\n","Epoch: 799, Train_loss: 12278.498046875\n","Epoch: 899, Train_loss: 11704.5908203125\n","Epoch: 999, Train_loss: 11165.5224609375\n"]}]},{"cell_type":"markdown","source":["# Sequential API"],"metadata":{"id":"uXUVAYWvEAlV"}},{"cell_type":"code","source":["model = torch.nn.Sequential(\n","    torch.nn.Linear(D_in, H),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(H, D_out),\n",")"],"metadata":{"id":"Yx8U65LLDy_4","executionInfo":{"status":"ok","timestamp":1707183933303,"user_tz":-540,"elapsed":605,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["loss_fn = torch.nn.MSELoss(reduction = \"mean\")\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"],"metadata":{"id":"JfpUlTloEgP6","executionInfo":{"status":"ok","timestamp":1707183968247,"user_tz":-540,"elapsed":1789,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["model = model.to(device)"],"metadata":{"id":"tNkGiKZNF8ZA","executionInfo":{"status":"ok","timestamp":1707183968262,"user_tz":-540,"elapsed":33,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["for i in range(1000):\n","    y_pred = model(x)\n","\n","    loss = loss_fn(y_pred, y)\n","    if i % 100 == 99:\n","        print(f\"Epoch: {i}, Train_loss: {loss.item()}\")\n","\n","    loss.backward() # This call will compute the gradient of loss with repect to all Tensors with requires_grad=True.\n","\n","    optimizer.step()\n","\n","    optimizer.zero_grad()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-ueCdh_EYMa","executionInfo":{"status":"ok","timestamp":1707183969828,"user_tz":-540,"elapsed":1598,"user":{"displayName":"해빈임","userId":"11652320193016134538"}},"outputId":"5343c337-3eb6-4444-a516-dd2ed139f8c2"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 99, Train_loss: 1.0978702306747437\n","Epoch: 199, Train_loss: 1.0704118013381958\n","Epoch: 299, Train_loss: 1.0436511039733887\n","Epoch: 399, Train_loss: 1.0175504684448242\n","Epoch: 499, Train_loss: 0.9921068549156189\n","Epoch: 599, Train_loss: 0.9673351645469666\n","Epoch: 699, Train_loss: 0.9432883262634277\n","Epoch: 799, Train_loss: 0.9198999404907227\n","Epoch: 899, Train_loss: 0.8971487283706665\n","Epoch: 999, Train_loss: 0.8751077055931091\n"]}]},{"cell_type":"markdown","source":["# Cutomize nn Modules using Subclassing API"],"metadata":{"id":"qNEZ-LTJGnqM"}},{"cell_type":"code","source":["class TwoLayerNet(torch.nn.Module):\n","    def __init__(self, D_in, H, D_out):\n","        super(TwoLayerNet, self).__init__()\n","        self.linear1 = torch.nn.Linear(D_in, H)\n","        self.linear1_act = torch.nn.ReLU()\n","        self.linear2 = torch.nn.Linear(H, D_out)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x_act = self.linear1_act(x)\n","        y_pred = self.linear2(x_act)\n","        return y_pred"],"metadata":{"id":"mQGMPmYQE8fu","executionInfo":{"status":"ok","timestamp":1707184337704,"user_tz":-540,"elapsed":575,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["model = TwoLayerNet(D_in, H, D_out)"],"metadata":{"id":"Ims-fFwXHfr3","executionInfo":{"status":"ok","timestamp":1707184445845,"user_tz":-540,"elapsed":18,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["model = model.to(device)"],"metadata":{"id":"efg18Km9H3It","executionInfo":{"status":"ok","timestamp":1707184460785,"user_tz":-540,"elapsed":583,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["loss_fn = torch.nn.MSELoss(reduction = \"mean\")\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"],"metadata":{"id":"VwrVbwGYIMhs","executionInfo":{"status":"ok","timestamp":1707184542250,"user_tz":-540,"elapsed":419,"user":{"displayName":"해빈임","userId":"11652320193016134538"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["for i in range(1000):\n","    y_pred = model(x)\n","\n","    loss = loss_fn(y_pred, y)\n","    if i % 100 == 99:\n","        print(f\"Epoch: {i}, Train_loss: {loss.item()}\")\n","\n","    loss.backward() # This call will compute the gradient of loss with repect to all Tensors with requires_grad=True.\n","\n","    optimizer.step()\n","\n","    optimizer.zero_grad()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3jR5hOOHa7D","executionInfo":{"status":"ok","timestamp":1707184545010,"user_tz":-540,"elapsed":971,"user":{"displayName":"해빈임","userId":"11652320193016134538"}},"outputId":"a644c5a8-d658-4f59-d1f1-e3ff6f063763"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 99, Train_loss: 1.1699904203414917\n","Epoch: 199, Train_loss: 1.169812560081482\n","Epoch: 299, Train_loss: 1.1695799827575684\n","Epoch: 399, Train_loss: 1.1692966222763062\n","Epoch: 499, Train_loss: 1.1689658164978027\n","Epoch: 599, Train_loss: 1.1685903072357178\n","Epoch: 699, Train_loss: 1.1681727170944214\n","Epoch: 799, Train_loss: 1.1677093505859375\n","Epoch: 899, Train_loss: 1.167202115058899\n","Epoch: 999, Train_loss: 1.1666496992111206\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"D4wnNrUxH1_6"},"execution_count":null,"outputs":[]}]}